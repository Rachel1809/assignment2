{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@449.878] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(-1)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow(\"frame\", hsv)\n",
    "        \n",
    "        lower_red = np.array([0, 20, 0])\n",
    "        upper_red = np.array([20, 200, 200])\n",
    "        \n",
    "        mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "        \n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "        dilation = cv2.dilate(mask, kernel, iterations=1)\n",
    "        \n",
    "        # opening aim to remove false positives (noise in the background)\n",
    "        # closing aim to remove false negatives (missing pixel in the foreground)\n",
    "        \n",
    "        opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"mask\", mask)\n",
    "        cv2.imshow(\"res\", res)\n",
    "        # cv2.imshow(\"erosion\", erosion)\n",
    "        # cv2.imshow(\"dilation\", dilation)\n",
    "        cv2.imshow(\"opening\", opening)\n",
    "        cv2.imshow(\"closing\", closing)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        print(ret)\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img2 = cv2.imread(\"wu3.jpg\")\n",
    "\n",
    "dark_vest = (0, 0, 0)\n",
    "light_vest = (130, 200, 165)\n",
    "\n",
    "lab_img = cv2.cvtColor(img2, cv2.COLOR_BGR2LAB)\n",
    "mask_vest = cv2.inRange(lab_img, dark_vest, light_vest)\n",
    "\n",
    "hsv_img = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "dark_skin = (4, 44, 165)\n",
    "light_skin = (15, 117, 236)\n",
    "hsv_blur =  cv2.bilateralFilter(hsv_img, 15, 75, 75)\n",
    "mask_skin = cv2.inRange(hsv_blur, dark_skin, light_skin)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "sum = mask_vest + mask_skin\n",
    "closing = cv2.morphologyEx(sum, cv2.MORPH_CLOSE, kernel)\n",
    "opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)\n",
    "opening2 = cv2.morphologyEx(sum, cv2.MORPH_OPEN, kernel)\n",
    "erosion = cv2.erode(sum, kernel, iterations=1)\n",
    "dilation = cv2.dilate(sum, kernel, iterations=1)\n",
    "res = cv2.bitwise_and(img2, img2, mask=opening)\n",
    "rows, cols, channels = res.shape\n",
    "indent = 180\n",
    "img1 = cv2.imread(\"yeah3.jpg\")\n",
    "\n",
    "roi = img1[-rows:, indent:indent+cols]\n",
    "mask_inv = cv2.bitwise_not(opening)\n",
    "img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "dst = cv2.add(img1_bg, res)\n",
    "\n",
    "img1[-rows:, indent:indent+cols] = dst\n",
    "edges = cv2.Canny(img2, 100, 200)\n",
    "# cv2.imshow(\"mask\", mask_skin)\n",
    "# cv2.imshow(\"vest\", mask_vest)\n",
    "cv2.imshow(\"sum\", hsv_img)\n",
    "cv2.imshow(\"opening\", opening)\n",
    "cv2.imshow(\"res\", res)\n",
    "# cv2.imshow(\"closing\", closing)\n",
    "# cv2.imshow(\"erosion\", erosion)\n",
    "# cv2.imshow(\"dilation\", dilation)\n",
    "cv2.imshow(\"edge\", edges)\n",
    "# cv2.imshow(\"hsv\", hsv_img)\n",
    "# cv2.imshow(\"image\", res)\n",
    "# cv2.imshow(\"sum\", sum)\n",
    "cv2.imshow(\"img1\", img1)\n",
    "\n",
    "#cv2.imshow(\"mask\", mask_inv)\n",
    "# waitKey(0) will display the window infinitely until any keypress \n",
    "# (it is suitable for image display).\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"wu3.jpg\")\n",
    "img1 = cv2.imread(\"yeah3.jpg\")\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "rect = (5, 45, 335, 826)\n",
    "cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype(\"uint8\")\n",
    "img2 = img*mask2[:, :, np.newaxis]\n",
    "\n",
    "_, mask3 = cv2.threshold(mask2*255, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "roi = img1[-rows:, indent:indent+cols]\n",
    "mask_inv = cv2.bitwise_not(mask3)\n",
    "\n",
    "img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "img2_fg = cv2.bitwise_and(img2, img2, mask=mask3)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "\n",
    "dst = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "img1[-rows:, indent:indent+cols] = dst\n",
    "cv2.imshow(\"bg\", img1_bg)\n",
    "cv2.imshow(\"fg\", img2_fg)\n",
    "cv2.imshow(\"image\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@18945.391] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform thresholding to obtain the binary mask for segmentation\n",
    "    _, segmented_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Show the segmented mask\n",
    "    cv2.imshow('Segmented Mask', segmented_mask)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 16:01:40.646933: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 16:01:41.200257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (/root/miniconda3/envs/py310/lib/python3.10/collections/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmrcnn\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmrcnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m MaskRCNN\n\u001b[1;32m      6\u001b[0m \u001b[39m# Path to the Mask R-CNN model weights file (downloaded from the link above)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m MODEL_WEIGHTS_PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmask_rcnn_coco.h5\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/mrcnn/model.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mK\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mKL\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/utils/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m normalize\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmulti_gpu_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m multi_gpu_model\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/utils/multi_gpu_utils.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m concatenate\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Lambda\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/layers/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m InputLayer\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/engine/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnetwork\u001b[39;00m \u001b[39mimport\u001b[39;00m get_source_inputs\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/engine/training.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m standardize_weights\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m weighted_masked_objective\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_arrays\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_generator\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/engine/training_arrays.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_num_samples\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks \u001b[39mas\u001b[39;00m cbks\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m Progbar\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m slice_arrays\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/keras/callbacks.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m deque\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterable\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m Progbar\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (/root/miniconda3/envs/py310/lib/python3.10/collections/__init__.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mrcnn import utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "# Path to the Mask R-CNN model weights file (downloaded from the link above)\n",
    "MODEL_WEIGHTS_PATH = 'mask_rcnn_coco.h5'\n",
    "\n",
    "# Load the pre-trained Mask R-CNN model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=utils.Config())\n",
    "model.load_weights(MODEL_WEIGHTS_PATH, by_name=True)\n",
    "\n",
    "# Open the video capture (use 0 for webcam or provide the path to a video file)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for better performance (optional)\n",
    "    frame = cv2.resize(frame, None, fx=0.7, fy=0.7)\n",
    "\n",
    "    # Perform object detection and segmentation using Mask R-CNN\n",
    "    results = model.detect([frame], verbose=0)\n",
    "    r = results[0]\n",
    "\n",
    "    # Visualize the segmented regions with masks (only show the hand)\n",
    "    hand_mask = r['masks'][:, :, r['class_ids'] == 1]\n",
    "    hand_frame = np.where(hand_mask[:, :, 0], frame, [0, 0, 255])\n",
    "\n",
    "    # Display the original and segmented frames\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Segmented Hand', hand_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def segment_hand(frame):\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds of the skin color in HSV\n",
    "    lower_bound = np.array([0, 50, 20], dtype=np.uint8)\n",
    "    upper_bound = np.array([20, 255, 250], dtype=np.uint8)\n",
    "\n",
    "    # Create a binary mask by thresholding the HSV image based on skin color\n",
    "    skin_mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "    # Apply morphological operations to remove noise and smooth the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel)\n",
    "    skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Create a masked image by applying the skin mask to the original frame\n",
    "    masked_frame = cv2.bitwise_and(frame, frame, mask=skin_mask)\n",
    "\n",
    "    return hsv, skin_mask, masked_frame\n",
    "\n",
    "# Open the video capture (use 0 for webcam or provide the path to a video file)\n",
    "cap = cv2.VideoCapture(\"/home/rrn4hc/mnt/Deep Learning/archive/videoplayback.mp4\")\n",
    "#cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for better performance (optional)\n",
    "    frame = cv2.resize(frame, None, fx=0.7, fy=0.7)\n",
    "\n",
    "    # Segment the hand from the frame\n",
    "    hsv, segmented_mask, segmented_frame = segment_hand(frame)\n",
    "\n",
    "    # Display the original and segmented frames\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Segmented Mask', segmented_mask)\n",
    "    cv2.imshow('Segmented Hand', segmented_frame)\n",
    "    \n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    elif cv2.waitKey(10) & 0xFF == ord('p'):\n",
    "        cv2.waitKey(-1)\n",
    "\n",
    "# Release the video capture and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
